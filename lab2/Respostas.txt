3.1.1) 	a) PAPI_L1_DCM: L1 data cache misses.

    	b) *Plot no repo

		c)	1) 32 KB, porque a partir de um array com tamanho de 64KB, começa a haver uma grande quantidade de misses na cache.
			2) 64 B, porque a partir deste tamanho de bloco, a quantidade de misses começa a estagnar.
			3) 8 vias de associatividade. O primeiro tamanho do array que não cabe na cache a dividir pelo seu stride em que 
				a average miss-rate começa a ser 0, dá 8, que é o número de vias de associatividade.

3.1.2) 	a) Alterar linha 49 de "if (PAPI_add_event(EventSet, PAPI_L1_DCM) != PAPI_OK)" para "if (PAPI_add_event(EventSet, PAPI_L2_DCM) != PAPI_OK)"

		b) *Plot no repo

		c) 	1) 256KB, porque a partir de um array com tamanho de 256KB, começa a haver uma grande quantidade de misses na cache.
			2) 64 B, porque a partir deste tamanho de bloco, a quantidade de misses começa a estagnar.
			3) 8 vias de associatividade, por observação ao gráfico.

3.2.1)	a) 2 MB;

		b)	1076.646389
			2149.5865
			4977.822018
			1.511896

		c)	0.499138

3.2.2)	a)	33.567978
			2149.5822
			1745.747775
			0.530229

		b)	0.984384

		c)	34.649392
			2151.68095
			2472.790082
			0.751050

			No exemplo que inclui a transposição de matrizes, o tempo de execução baixou para 1/3 (não considerando a transposição)
			. Contudo, mesmo considerando o tempo da transposição, o tempo de execução baixou para metade. Logo podemos concluir, que
			vale a pena transpôr as matrizes antes da operação.

		d) 	D(hit-rate) = 0.984384 - 0.499138 = 0.485246
			Speedup = 1.511896 / 0.75105 = 2.01304

3.2.3)	a)	32 elementos

		b)	129.894236
			3256.637125
			2432.474581
			0.738806

		c)	0.96011

        d)	D(hit-rate) = 0.96011 - 0.499138 = 0.460976
			Speedup = 1.511896 / 0.738806 = 2.0464

        e)	D(hit-rate) = 0.96011 - 0.984384 = -0.024274
			Speedup = 0.751050 / 0.738806 = 1.01657


3.2.4)	Os resultados de tamanho de cache apresentados pelo comando são iguais aos calculados nas alíneas anteriores